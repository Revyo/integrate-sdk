---
title: Vercel AI SDK Integration
description: Give AI models access to all your integrations
---

The Integrate SDK includes seamless integration with Vercel's AI SDK, allowing AI models to access your integrations through MCP tools. Use it on the frontend with `useIntegrateAI` or on the server with `getVercelAITools`.

## Frontend Integration with `useIntegrateAI`

The easiest way to integrate with Vercel AI SDK on the frontend is using the `useIntegrateAI` hook. It automatically injects provider tokens into all AI SDK requests.

### Complete Setup

```typescript
// app/providers.tsx (or app/layout.tsx)
'use client';

import { createMCPClient, githubPlugin } from 'integrate-sdk';
import { useIntegrateAI } from 'integrate-sdk/react';

const client = createMCPClient({
  plugins: [
    githubPlugin({
      clientId: process.env.NEXT_PUBLIC_GITHUB_CLIENT_ID!,
    }),
  ],
});

export function Providers({ children }: { children: React.ReactNode }) {
  // Install global fetch interceptor once at app root
  useIntegrateAI(client);
  
  return <>{children}</>;
}
```

Now any component can use Vercel AI SDK's `useChat` hook without manual token management:

```typescript
// app/chat/page.tsx
'use client';

import { useChat } from 'ai/react';

export default function ChatPage() {
  const { messages, input, handleInputChange, handleSubmit } = useChat({
    api: '/api/chat', // Tokens automatically injected!
  });
  
  return (
    <div>
      <div>
        {messages.map((m) => (
          <div key={m.id}>
            <strong>{m.role}:</strong> {m.content}
          </div>
        ))}
      </div>
      <form onSubmit={handleSubmit}>
        <input value={input} onChange={handleInputChange} />
        <button type="submit">Send</button>
      </form>
    </div>
  );
}
```

### How `useIntegrateAI` Works

The hook installs a global `window.fetch` interceptor that:

1. **Detects AI SDK requests** using a URL pattern (default: `/api/chat`)
2. **Injects provider tokens** automatically from the MCP client
3. **Updates tokens** when OAuth events occur (auth, disconnect, logout)
4. **Passes through** all other requests unchanged

```typescript
// Customize the interceptor behavior
useIntegrateAI(client, {
  apiPattern: /\/(api|chat)\//, // Match /api/ or /chat/ routes
  debug: true, // Enable debug logging
});
```

### Complete Frontend Example

```typescript
// app/providers.tsx
'use client';

import { createMCPClient, githubPlugin, gmailPlugin } from 'integrate-sdk';
import { useIntegrateAI } from 'integrate-sdk/react';

const client = createMCPClient({
  plugins: [
    githubPlugin({ clientId: process.env.NEXT_PUBLIC_GITHUB_CLIENT_ID! }),
    gmailPlugin({ clientId: process.env.NEXT_PUBLIC_GMAIL_CLIENT_ID! }),
  ],
  oauthFlow: { mode: 'popup' },
});

export function Providers({ children }: { children: React.ReactNode }) {
  useIntegrateAI(client, {
    debug: process.env.NODE_ENV === 'development',
  });
  
  return <>{children}</>;
}
```

```typescript
// app/chat/page.tsx
'use client';

import { useChat } from 'ai/react';
import { useState, useEffect } from 'react';
import { createMCPClient, githubPlugin } from 'integrate-sdk';

const client = createMCPClient({
  plugins: [
    githubPlugin({ clientId: process.env.NEXT_PUBLIC_GITHUB_CLIENT_ID! }),
  ],
});

export default function ChatPage() {
  const [authorized, setAuthorized] = useState(false);
  
  useEffect(() => {
    client.isAuthorized('github').then(setAuthorized);
  }, []);
  
  const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat();
  
  if (!authorized) {
    return (
      <div>
        <h1>Connect GitHub</h1>
        <button onClick={() => client.authorize('github').then(() => setAuthorized(true))}>
          Connect GitHub
        </button>
      </div>
    );
  }
  
  return (
    <div>
      <h1>AI Chat with GitHub Access</h1>
      <div>
        {messages.map((m) => (
          <div key={m.id}>
            <strong>{m.role === 'user' ? 'You' : 'AI'}:</strong> {m.content}
          </div>
        ))}
      </div>
      <form onSubmit={handleSubmit}>
        <input 
          value={input} 
          onChange={handleInputChange}
          placeholder="Ask AI to use GitHub..."
          disabled={isLoading}
        />
        <button type="submit" disabled={isLoading}>
          {isLoading ? 'Thinking...' : 'Send'}
        </button>
      </form>
    </div>
  );
}
```

## Server-Side Integration with `getVercelAITools`

Use `getVercelAITools` in your API routes to convert MCP tools into Vercel AI SDK format. The frontend automatically sends tokens via the `useIntegrateAI` hook.

### Flow Overview

1. **Frontend**: User authorizes via OAuth, `useIntegrateAI` manages tokens
2. **Frontend → Server**: Tokens automatically sent in `x-integrate-tokens` header
3. **Server**: Uses `getVercelAITools` with provider tokens to execute tools
4. **Server → Frontend**: AI response streamed back

### Server Setup

First, create your server configuration file:

```typescript
// lib/integrate-server.ts
import { createMCPServer, githubPlugin, gmailPlugin } from 'integrate-sdk/server';

export const { client: serverClient } = createMCPServer({
  plugins: [
    githubPlugin({
      clientId: process.env.GITHUB_CLIENT_ID!,
      clientSecret: process.env.GITHUB_CLIENT_SECRET!,
      scopes: ['repo', 'user'],
    }),
    gmailPlugin({
      clientId: process.env.GMAIL_CLIENT_ID!,
      clientSecret: process.env.GMAIL_CLIENT_SECRET!,
      scopes: ['gmail.send', 'gmail.readonly'],
    }),
  ],
});
```

### Chat API Route

Create a chat route that receives tokens from the frontend:

```typescript
// app/api/chat/route.ts
import { serverClient } from '@/lib/integrate-server';
import { getVercelAITools } from 'integrate-sdk';
import { streamText } from 'ai';
import { openai } from '@ai-sdk/openai';

export async function POST(req: Request) {
  try {
    // 1. Extract provider tokens from request header
    // These are automatically injected by useIntegrateAI on the frontend
    const tokensHeader = req.headers.get('x-integrate-tokens');
    
    if (!tokensHeader) {
      return Response.json(
        { error: 'Authentication required' },
        { status: 401 }
      );
    }

    const providerTokens = JSON.parse(tokensHeader);
    // { github: 'ghp_...', gmail: 'ya29...' }

    // 2. Get tools with user's provider tokens
    // The serverClient was created in lib/integrate-server.ts
    // getVercelAITools automatically connects if needed
    const tools = await getVercelAITools(serverClient, { providerTokens });

    // 3. Parse request body from useChat
    const { messages } = await req.json();

    // 4. Stream AI response with tools
    const result = await streamText({
      model: openai('gpt-4'),
      messages,
      tools,
      maxToolRoundtrips: 5,
    });

    // 5. Return streaming response
    return result.toTextStreamResponse();
  } catch (error: any) {
    console.error('[AI Chat] Error:', error);
    return Response.json(
      { error: error.message || 'Internal server error' },
      { status: 500 }
    );
  }
}
```

That's it! The complete integration:

1. **Frontend**: `useIntegrateAI` automatically sends tokens
2. **Server**: `getVercelAITools` uses tokens to execute tools
3. **AI**: Calls tools with user's permissions

### Non-Streaming Example

If you prefer non-streaming responses:

```typescript
// app/api/chat/route.ts
import { serverClient } from '@/lib/integrate-server';
import { getVercelAITools } from 'integrate-sdk';
import { generateText } from 'ai';
import { openai } from '@ai-sdk/openai';

export async function POST(req: Request) {
  try {
    const tokensHeader = req.headers.get('x-integrate-tokens');
    const providerTokens = JSON.parse(tokensHeader || '{}');

    // Get tools with user's tokens
    const tools = await getVercelAITools(serverClient, { providerTokens });

    const { messages } = await req.json();

    // Generate complete response
    const result = await generateText({
      model: openai('gpt-4'),
      messages,
      tools,
      maxToolRoundtrips: 5,
    });

    return Response.json({
      message: result.text,
      toolCalls: result.toolCalls,
    });
  } catch (error: any) {
    return Response.json(
      { error: error.message },
      { status: 500 }
    );
  }
}
```

### Manual Token Injection (Without `useIntegrateAI`)

If you prefer not to use the hook, you can manually send tokens:

```typescript
// Client-side
import { createMCPClient, githubPlugin } from 'integrate-sdk';

const client = createMCPClient({
  plugins: [githubPlugin({ clientId: process.env.NEXT_PUBLIC_GITHUB_CLIENT_ID! })],
});

await client.authorize('github');

// Get all provider tokens manually
const providerTokens = client.getAllProviderTokens();

// Send to server manually
const response = await fetch('/api/chat', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'x-integrate-tokens': JSON.stringify(providerTokens),
  },
  body: JSON.stringify({
    messages: [
      { role: 'user', content: 'Create a GitHub issue' }
    ],
  }),
});
```

## Security Best Practices

1. **OAuth Secrets**: Never expose `clientSecret` to the client
2. **Token Validation**: Validate tokens on every server request
3. **HTTPS Only**: Always use HTTPS for token transmission
4. **Rate Limiting**: Implement per-user rate limits
5. **Token Encryption**: Consider encrypting tokens in transit

## Installation

You need both the Integrate SDK and Vercel AI SDK:

```bash
bun add integrate-sdk ai @ai-sdk/openai
```

## How It Works

The integration works by:

1. **Converting MCP tools to Vercel AI format** using Zod schemas
2. **Injecting provider tokens** into tool execution calls
3. **Streaming responses** back to the client

```typescript
// Behind the scenes, getVercelAITools does this:
const tools = {
  github_create_issue: {
    description: "Create a new issue in a GitHub repository",
    inputSchema: z.object({
      owner: z.string(),
      repo: z.string(),
      title: z.string(),
      body: z.string().optional(),
    }),
    execute: async (args) => {
      // Uses provider token from options
      return await client._callToolByName("github_create_issue", args);
    },
  },
  // ... more tools
};
```

## API Reference

### `getVercelAITools(client, options?)`

Converts all enabled MCP tools to Vercel AI SDK format.

```typescript
function getVercelAITools(
  client: MCPClient,
  options?: VercelAIToolsOptions
): Promise<Record<string, VercelAITool>>;
```

**Parameters:**

- `client` - The MCP client instance
- `options` - Optional configuration (see `VercelAIToolsOptions` below)

<AutoTypeTable
  path="../src/integrations/vercel-ai.ts"
  name="VercelAIToolsOptions"
/>

**Returns:** `Record<string, VercelAITool>` - Tools ready for use with `generateText` or `streamText`

**Example:**

```typescript
// Client-side
const tools = await getVercelAITools(client);

// Server-side with provider tokens
const tools = await getVercelAITools(serverClient, { 
  providerTokens: { github: 'ghp_...', gmail: 'ya29...' } 
});
```

### `useIntegrateAI(client?, options?)`

React hook that installs a global fetch interceptor for automatic token injection.

```typescript
function useIntegrateAI(
  client?: MCPClient | null,
  options?: UseIntegrateAIOptions
): void;
```

**Parameters:**

- `client` - The MCP client instance (optional)
- `options` - Configuration options (see `UseIntegrateAIOptions` below)

<AutoTypeTable path="../src/react/hooks.ts" name="UseIntegrateAIOptions" />

**Example:**

```typescript
useIntegrateAI(client, {
  apiPattern: /\/api\/chat/,
  debug: true,
});
```

## Advanced Usage

### Filtering Tools

Expose only specific tools to the AI:

```typescript
const allTools = await getVercelAITools(client);

// Only GitHub tools
const githubTools = Object.fromEntries(
  Object.entries(allTools).filter(([name]) => name.startsWith("github_"))
);

const result = await generateText({
  model: openai("gpt-4"),
  prompt: "Work with GitHub",
  tools: githubTools,
});
```

### Error Handling

Handle tool execution errors:

```typescript
try {
  const result = await generateText({
    model: openai("gpt-4"),
    prompt: "Create a GitHub issue",
    tools,
    maxToolRoundtrips: 5,
  });

  console.log(result.text);
} catch (error) {
  console.error("Generation error:", error);
}
```

### Custom API Patterns

Match multiple API routes:

```typescript
useIntegrateAI(client, {
  apiPattern: /\/(api|chat|ai)\//,
});
```

## Complete Example

Here's a full example with both frontend and backend:

```typescript
// lib/integrate-server.ts
import { createMCPServer, githubPlugin } from 'integrate-sdk/server';

export const { client: serverClient } = createMCPServer({
  plugins: [
    githubPlugin({
      clientId: process.env.GITHUB_CLIENT_ID!,
      clientSecret: process.env.GITHUB_CLIENT_SECRET!,
    }),
  ],
});
```

```typescript
// app/providers.tsx
'use client';

import { createMCPClient, githubPlugin } from 'integrate-sdk';
import { useIntegrateAI } from 'integrate-sdk/react';

const client = createMCPClient({
  plugins: [
    githubPlugin({ clientId: process.env.NEXT_PUBLIC_GITHUB_CLIENT_ID! }),
  ],
});

export function Providers({ children }: { children: React.ReactNode }) {
  useIntegrateAI(client);
  return <>{children}</>;
}
```

```typescript
// app/api/chat/route.ts
import { serverClient } from '@/lib/integrate-server';
import { getVercelAITools } from 'integrate-sdk';
import { streamText } from 'ai';
import { openai } from '@ai-sdk/openai';

export async function POST(req: Request) {
  const tokensHeader = req.headers.get('x-integrate-tokens');
  const providerTokens = JSON.parse(tokensHeader || '{}');

  const tools = await getVercelAITools(serverClient, { providerTokens });
  const { messages } = await req.json();

  const result = await streamText({
    model: openai('gpt-4'),
    messages,
    tools,
    maxToolRoundtrips: 5,
  });

  return result.toTextStreamResponse();
}
```

```typescript
// app/chat/page.tsx
'use client';

import { useChat } from 'ai/react';

export default function ChatPage() {
  const { messages, input, handleInputChange, handleSubmit } = useChat();
  
  return (
    <div>
      {messages.map((m) => (
        <div key={m.id}>
          <strong>{m.role}:</strong> {m.content}
        </div>
      ))}
      <form onSubmit={handleSubmit}>
        <input value={input} onChange={handleInputChange} />
        <button type="submit">Send</button>
      </form>
    </div>
  );
}
```

## Next Steps

- Set up [OAuth routes in Next.js](/docs/oauth/nextjs)
- Explore [Advanced Configuration](/docs/getting-started/advanced-usage)
- Check the [API Reference](/docs/reference/options) for complete type definitions
